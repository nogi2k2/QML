{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "xBSoJuk-YX2-",
        "L0JVY7_xYTua",
        "DvGPyfvsY4FH",
        "kMko8N6ha-19",
        "tyGflm5x0H48",
        "ax1GmPGn3hnl",
        "7jzjSqXhn5Vp",
        "W1_BRSusZZMX",
        "vTirzz1ArZ1R",
        "5wHc_nu3ITLq",
        "qvRycYz9rG81",
        "MjYGEijbc7yy",
        "Ce4aLIso4byH",
        "eESQkrqgUsle",
        "eZgdRPDVUxX3",
        "VODeSsL-4dSr",
        "aJUnYQXIhCuw",
        "Stu8Vrh9hL9k",
        "5r-VF2IWe1lJ"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Imports and Downloads**"
      ],
      "metadata": {
        "id": "xBSoJuk-YX2-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nind1MPQVDFp",
        "outputId": "7fc3f3c3-709c-4f64-e3e8-4382433e7e8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 2.0.2\n",
            "Uninstalling numpy-2.0.2:\n",
            "  Successfully uninstalled numpy-2.0.2\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting pennylane\n",
            "  Downloading pennylane-0.42.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting pennylane-lightning\n",
            "  Downloading pennylane_lightning-0.42.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.16.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from pennylane) (3.5)\n",
            "Collecting rustworkx>=0.14.0 (from pennylane)\n",
            "  Downloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.8.0)\n",
            "Collecting appdirs (from pennylane)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting autoray>=0.6.11 (from pennylane)\n",
            "  Downloading autoray-0.7.2-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from pennylane) (5.5.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from pennylane) (2.32.3)\n",
            "Requirement already satisfied: tomlkit in /usr/local/lib/python3.11/dist-packages (from pennylane) (0.13.3)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from pennylane) (4.14.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pennylane) (25.0)\n",
            "Collecting diastatic-malt (from pennylane)\n",
            "  Downloading diastatic_malt-2.15.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.26.4)\n",
            "Collecting scipy-openblas32>=0.3.26 (from pennylane-lightning)\n",
            "  Downloading scipy_openblas32-0.3.30.0.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.1/57.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: astunparse in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (1.6.3)\n",
            "Requirement already satisfied: gast in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (0.6.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (3.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (2025.7.14)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse->diastatic-malt->pennylane) (0.45.1)\n",
            "Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from astunparse->diastatic-malt->pennylane) (1.17.0)\n",
            "Downloading pennylane-0.42.0-py3-none-any.whl (4.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pennylane_lightning-0.42.0-cp311-cp311-manylinux_2_28_x86_64.whl (2.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m91.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autoray-0.7.2-py3-none-any.whl (930 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m930.8/930.8 kB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy_openblas32-0.3.30.0.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m89.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading diastatic_malt-2.15.2-py3-none-any.whl (167 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: appdirs, scipy-openblas32, rustworkx, autoray, diastatic-malt, pennylane-lightning, pennylane\n",
            "Successfully installed appdirs-1.4.4 autoray-0.7.2 diastatic-malt-2.15.2 pennylane-0.42.0 pennylane-lightning-0.42.0 rustworkx-0.16.0 scipy-openblas32-0.3.30.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y numpy\n",
        "!pip install numpy==1.26.4 --upgrade --force-reinstall --quiet\n",
        "!pip install --upgrade pennylane pennylane-lightning"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "7SIA-uaBVEDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqZ-dh-NVFkq",
        "outputId": "ad6bb095-e050-4dd6-f1b5-632706e94f8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Core libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import math\n",
        "import re\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "\n",
        "# Quantum computing\n",
        "import pennylane as qml\n",
        "from pennylane import numpy as pnp\n",
        "from pennylane.optimize import AdamOptimizer\n",
        "\n",
        "# NLP and preprocessing\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.util import ngrams\n",
        "\n",
        "# Sklearn tools\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "# Reproducibility\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "pnp.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "emjwDqgTVFhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Loading and Preprocessing**"
      ],
      "metadata": {
        "id": "L0JVY7_xYTua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/QML-Research/Data/sentiment labelled sentences/amazon_cells_labelled.txt\", \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "sentences = [line.split(\"\\t\")[0] for line in lines]\n",
        "labels = [int(line.split(\"\\t\")[1]) for line in lines]"
      ],
      "metadata": {
        "id": "IDJ9A_o7VFbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"stopwords\")\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "domain_neutral_words = {\n",
        "    \"phone\", \"product\", \"battery\", \"headset\", \"quality\", \"one\", \"use\"\n",
        "}\n",
        "stop_words.update(domain_neutral_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwR5eTa0YlFp",
        "outputId": "26ea8776-919d-490f-fc2f-dd8c675bb634"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_and_tokenize(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"http\\S+\", \"\", text)\n",
        "    text = re.sub(r\"[^a-z0-9\\s]\", \"\", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    tokens = text.split()\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    return tokens\n",
        "\n",
        "cleaned_sents = [clean_and_tokenize(sentence) for sentence in sentences]"
      ],
      "metadata": {
        "id": "IbJX9uXlVFZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 10\n",
        "for i in range(len(cleaned_sents)):\n",
        "  if (len(cleaned_sents[i]) < max_len):\n",
        "    cleaned_sents[i] += [\"<PAD>\"] * (max_len - len(cleaned_sents[i]))\n",
        "  else:\n",
        "    cleaned_sents[i] = cleaned_sents[i][:max_len]"
      ],
      "metadata": {
        "id": "jommbUzPVFTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GloVE Word Embeddings**"
      ],
      "metadata": {
        "id": "DvGPyfvsY4FH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_glove_embeddings(file_path):\n",
        "    embeddings = {}\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.strip().split()\n",
        "            word = values[0]\n",
        "            vector = np.array(values[1:], dtype='float32')\n",
        "            embeddings[word] = vector\n",
        "    return embeddings"
      ],
      "metadata": {
        "id": "KJfUcJaRVFQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glove_path = '/content/drive/MyDrive/QML-Research/Data/glove.6B.100d.txt'\n",
        "glove = load_glove_embeddings(glove_path)"
      ],
      "metadata": {
        "id": "Z40kR5fWZ_0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **AutoEncoder**"
      ],
      "metadata": {
        "id": "kMko8N6ha-19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GloVeAutoencoder(nn.Module):\n",
        "    def __init__(self, input_dim, latent_dim):\n",
        "        super(GloVeAutoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, latent_dim)\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, input_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded"
      ],
      "metadata": {
        "id": "zxYOHIgrVFIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_words = list(glove.keys())\n",
        "all_vectors = np.array([glove[word] for word in all_words])\n",
        "all_vectors = normalize(all_vectors)\n",
        "word_tensor = torch.tensor(all_vectors).float()"
      ],
      "metadata": {
        "id": "FKWwxltMVFF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 8\n",
        "epochs = 100\n",
        "save_path = '/content/drive/MyDrive/QML-Research/Autoencoder/glove_autoencoder_normalized_8.pth'\n",
        "# save_path = '/content/drive/MyDrive/QML-Research/Autoencoder/glove_autoencoder_normalized_32.pth'"
      ],
      "metadata": {
        "id": "HfGzHVQP0h6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(save_path):\n",
        "    print(f\"Loading Autoencoder from {save_path}\")\n",
        "    autoencoder = GloVeAutoencoder(input_dim=100, latent_dim=latent_dim)\n",
        "    autoencoder.load_state_dict(torch.load(save_path, map_location=torch.device('cpu')))\n",
        "else:\n",
        "    print(\"Training Autoencoder\")\n",
        "    autoencoder = GloVeAutoencoder(input_dim=100, latent_dim=latent_dim)\n",
        "    optimizer = torch.optim.Adam(autoencoder.parameters(), lr=1e-3)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        optimizer.zero_grad()\n",
        "        reconstructed = autoencoder(word_tensor)\n",
        "        loss = criterion(reconstructed, word_tensor)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            print(f\"Epoch {epoch}, Loss: {loss.item():.6f}\")\n",
        "\n",
        "    torch.save(autoencoder.state_dict(), save_path)\n",
        "    print(f\"Saved Autoencoder serialized model in drive @ {save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUDeGZHIVFC2",
        "outputId": "8ffc5631-4387-4976-ab22-10774c28c194"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Autoencoder from /content/drive/MyDrive/QML-Research/Autoencoder/glove_autoencoder_normalized_8.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.eval()\n",
        "with torch.no_grad():\n",
        "    compressed_vectors = autoencoder.encoder(word_tensor).numpy()\n",
        "\n",
        "reduced_embeddings = {\n",
        "    word: compressed_vectors[i]\n",
        "    for i, word in enumerate(all_words)\n",
        "}"
      ],
      "metadata": {
        "id": "eZYs04ccVE_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Embedding**"
      ],
      "metadata": {
        "id": "tyGflm5x0H48"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_to_vec(sentence, embeddings, dim):\n",
        "    vectors = []\n",
        "    for word in sentence:\n",
        "        if word in embeddings:\n",
        "            vectors.append(embeddings[word])\n",
        "        else:\n",
        "            vectors.append(np.zeros(dim))\n",
        "    return vectors\n",
        "\n",
        "def embed_sentences(cleaned_sents, embeddings, dim):\n",
        "    return np.array([sentence_to_vec(tokens, embeddings, dim) for tokens in cleaned_sents])"
      ],
      "metadata": {
        "id": "LHyTknfpVhiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_embed_np = embed_sentences(cleaned_sents, reduced_embeddings, dim=8)\n",
        "X_embed_np = (X_embed_np - X_embed_np.min()) * (np.pi / (X_embed_np.max() - X_embed_np.min()))\n",
        "\n",
        "X_embed = torch.tensor(X_embed_np).long()\n",
        "y_embed = torch.tensor(labels).long()"
      ],
      "metadata": {
        "id": "PtDZbVTTVhfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataset and DataLoader**"
      ],
      "metadata": {
        "id": "ax1GmPGn3hnl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AmazonDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]"
      ],
      "metadata": {
        "id": "KZP80femFVRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_embed, y_embed, test_size=0.2, stratify=y_embed.numpy(), random_state=42\n",
        ")\n",
        "\n",
        "train_dataset = AmazonDataset(X_train, y_train)\n",
        "test_dataset = AmazonDataset(X_test, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1)"
      ],
      "metadata": {
        "id": "tLSMr6nta7Ki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Utility Functions**"
      ],
      "metadata": {
        "id": "7jzjSqXhn5Vp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(logits):\n",
        "    logits = qml.numpy.array(logits)\n",
        "    logits = logits - qml.numpy.max(logits)\n",
        "    exps = qml.numpy.exp(logits)\n",
        "    return exps / qml.numpy.sum(exps)\n",
        "\n",
        "def cross_entropy(label, probs):\n",
        "    p = qml.numpy.clip(probs[label], 1e-10, 1.0)\n",
        "    return -qml.numpy.log(p)\n",
        "\n",
        "# def reshape_params(flat_params):\n",
        "#     wpw = flat_params[:80].reshape((10, 8))\n",
        "#     clf = flat_params[80:].reshape((8,))\n",
        "#     return wpw, clf"
      ],
      "metadata": {
        "id": "o_qhLqOXn5GC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **QRNN Model Layers**"
      ],
      "metadata": {
        "id": "W1_BRSusZZMX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "First Variation of QRNN that showed learning during training, Achieving a training accuracy of 67% (Highest)\n",
        "and a peak testing accuracy of 55.5% with a training duration of 50-60 epochs. The layers have been split\n",
        "into Unitary and entanglement and have been implemnted as functions. This model processes the whole sequence\n",
        "(All Timesteps) at once in contrast to the previous iterations that processes one time-step/word at a time.\n",
        "\"\"\"\n",
        "\n",
        "# def dense_angle_embedding(x, wires):\n",
        "#     # For 32 dim:\n",
        "#     # chunk_size = 8\n",
        "#     chunk_size = 2\n",
        "\n",
        "#     for i, wire in enumerate(wires):\n",
        "#         for j in range(chunk_size):\n",
        "#             idx = i * chunk_size + j\n",
        "#             qml.RX(x[idx], wires=wire)\n",
        "#             qml.RY(x[idx], wires=wire)\n",
        "#             qml.RZ(x[idx], wires=wire)\n",
        "\n",
        "# def variational_block(weights, wires):\n",
        "#     for i, wire in enumerate(wires):\n",
        "#         qml.RY(weights[i], wires=wire)\n",
        "#         qml.RZ(weights[i + len(wires)], wires=wire)\n",
        "\n",
        "# def entangle(wires):\n",
        "#     for i in range(len(wires) - 1):\n",
        "#         qml.CNOT(wires=[wires[i], wires[i + 1]])\n",
        "#     qml.CNOT(wires=[wires[-1], wires[0]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhwchF8tZgac",
        "outputId": "659f3b80-c975-49e3-8958-413fcd076008"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nFirst Variation of QRNN that showed learning during training, Achieving a training accuracy of 67% (Highest)\\nand a peak testing accuracy of 55.5% with a training duration of 50-60 epochs. The layers have been split\\ninto Unitary and entanglement and have been implemnted as functions. This model processes the whole sequence\\n(All Timesteps) at once in contrast to the previous iterations that processes one time-step/word at a time.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "The second iteration of the previous model introducing major architectural changes (All layers are implemented as functions):\n",
        "a. Stacked QRNN (2 layered QRNN), with each QRB having seperate weights (No weight sharing)\n",
        "b. Interaction layers implemented seperate from the QRBs (Quantum Recurrent Block)\n",
        "c. Introduced an additional interaction layer (classification layer) before quantum measurement\n",
        "\"\"\"\n",
        "\n",
        "def input_layer(x_sequence, wires):\n",
        "    for word_vec in x_sequence:\n",
        "        for i, wire in enumerate(wires):\n",
        "            qml.RX(word_vec[2 * i], wires=wire)\n",
        "            qml.RY(word_vec[2 * i + 1], wires=wire)\n",
        "            qml.RZ(word_vec[2 * i], wires=wire)\n",
        "\n",
        "# def qrnn_layer(weights, wires):\n",
        "#     for i, wire in enumerate(wires):\n",
        "#         qml.RY(weights[i], wires=wire)\n",
        "#         qml.RZ(weights[i + len(wires)], wires=wire)\n",
        "\n",
        "def qrnn_layer(weights, wires):\n",
        "    for i, wire in enumerate(wires):\n",
        "        qml.Rot(weights[i, 0], weights[i, 1], weights[i, 2], wires=wire)\n",
        "\n",
        "def interaction_layer(wires):\n",
        "    for i in range(len(wires)):\n",
        "        qml.CNOT(wires=[wires[i], wires[(i + 1) % len(wires)]])\n",
        "\n",
        "# def final_interaction_layer(weights, wires):\n",
        "#     for i, wire in enumerate(wires):\n",
        "#         qml.RY(weights[i], wires=wire)\n",
        "#         qml.RZ(weights[i + len(wires)], wires=wire)\n",
        "\n",
        "# def final_interaction_layer(weights, wires):\n",
        "#     for i, wire in enumerate(wires):\n",
        "#         qml.Rot(*weights[i], wires=wire)\n",
        "\n",
        "def final_interaction_layer(w, wires):\n",
        "    for i in range(len(wires) - 1):\n",
        "        qml.CNOT(wires=[wires[i], wires[i + 1]])\n",
        "\n",
        "    for i in range(len(wires)):\n",
        "        qml.Rot(w[i, 0], w[i, 1], w[i, 2], wires=wires[i])"
      ],
      "metadata": {
        "id": "283pXFYTZhxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model**"
      ],
      "metadata": {
        "id": "vTirzz1ArZ1R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def forward(input_sequence, weights_in, weights_h, hidden_init=None):\n",
        "#     \"\"\"\n",
        "#     input_sequence: (10, 32) numpy array\n",
        "#     weights_in: (6,) numpy array\n",
        "#     weights_h: (2,) numpy array\n",
        "#     hidden_init: optional scalar float, default is small random value\n",
        "#     \"\"\"\n",
        "#     if hidden_init is None:\n",
        "#         hidden = np.random.uniform(-0.1, 0.1)\n",
        "#     else:\n",
        "#         hidden = hidden_init\n",
        "\n",
        "#     for word_vec in input_sequence:\n",
        "#         logits = quantum_step(word_vec, hidden, weights_in, weights_h)\n",
        "#         hidden = np.tanh(logits[0] + logits[1])\n",
        "\n",
        "#     return logits"
      ],
      "metadata": {
        "id": "j4KRWY_MZhof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def qrnn_model(x_sequence, flat_params, wires):\n",
        "    w_qrb1 = flat_params[:12].reshape((4, 3))\n",
        "    w_qrb2 = flat_params[12:24].reshape((4, 3))\n",
        "    w_qrb3 = flat_params[24:36].reshape((4, 3))\n",
        "    w_classifier = flat_params[36:].reshape((4, 3))\n",
        "\n",
        "    input_layer(x_sequence, wires)\n",
        "\n",
        "    qrnn_layer(w_qrb1, wires)\n",
        "    # interaction_layer(wires)\n",
        "\n",
        "    qrnn_layer(w_qrb2, wires)\n",
        "    # interaction_layer(wires)\n",
        "\n",
        "    qrnn_layer(w_qrb3, wires)\n",
        "    # interaction_layer(wires)\n",
        "\n",
        "    final_interaction_layer(w_classifier, wires)"
      ],
      "metadata": {
        "id": "_BQXE4pJrfhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def qrnn_model(x_sequence, flat_params, wires, mode=\"full\"):\n",
        "#   # Phase 1\n",
        "#     if mode == \"phase1\":\n",
        "#         w_qrb1 = flat_params[:12].reshape((4, 3))\n",
        "#         w_qrb1 = qml.numpy.array(w_qrb1, requires_grad=True)\n",
        "\n",
        "#         input_layer(x_sequence, wires)\n",
        "#         qrnn_layer(w_qrb1, wires)\n",
        "#         interaction_layer(wires)\n",
        "\n",
        "#     # Phase 2\n",
        "#     elif mode == \"phase2\":\n",
        "#         w_qrb1_raw = flat_params[:12].reshape((4, 3))\n",
        "#         w_qrb2_raw = flat_params[12:24].reshape((4, 3))\n",
        "\n",
        "#         w_qrb1 = qml.numpy.array(w_qrb1_raw, requires_grad=False)\n",
        "#         w_qrb2 = qml.numpy.array(w_qrb2_raw, requires_grad=True)\n",
        "\n",
        "#         input_layer(x_sequence, wires)\n",
        "#         qrnn_layer(w_qrb1, wires)\n",
        "#         interaction_layer(wires)\n",
        "#         qrnn_layer(w_qrb2, wires)\n",
        "#         interaction_layer(wires)\n",
        "\n",
        "\n",
        "#     # Phase 3\n",
        "#     elif mode == \"phase3\" or mode == \"full\":\n",
        "#         w_qrb1_raw = flat_params[:12].reshape((4, 3))\n",
        "#         w_qrb2_raw = flat_params[12:24].reshape((4, 3))\n",
        "#         w_classifier_raw = flat_params[24:].reshape((4, 3))\n",
        "\n",
        "#         w_qrb1 = qml.numpy.array(w_qrb1_raw, requires_grad=False)\n",
        "#         w_qrb2 = qml.numpy.array(w_qrb2_raw, requires_grad=False)\n",
        "#         w_classifier = qml.numpy.array(w_classifier_raw, requires_grad=True)\n",
        "\n",
        "#         input_layer(x_sequence, wires)\n",
        "#         qrnn_layer(w_qrb1, wires)\n",
        "#         interaction_layer(wires)\n",
        "#         qrnn_layer(w_qrb2, wires)\n",
        "#         interaction_layer(wires)\n",
        "#         final_interaction_layer(w_classifier, wires)"
      ],
      "metadata": {
        "id": "W0xNOSq-Ce6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **QNode**"
      ],
      "metadata": {
        "id": "5wHc_nu3ITLq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dev_test = qml.device(\"lightning.qubit\", wires=4, shots=10000)\n",
        "# @qml.qnode(dev_test, interface=\"autograd\")\n",
        "# def stacked_qrnn_test(x_sequence, flat_params):\n",
        "#     wires = list(range(n_qubits))\n",
        "#     qrnn_model(x_sequence, flat_params, wires)\n",
        "#     return qml.expval(qml.PauliZ(wires[2])), qml.expval(qml.PauliZ(wires[3]))"
      ],
      "metadata": {
        "id": "M1VqErPsRjAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_qubits = 4\n",
        "# dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "dev_train = qml.device(\"lightning.qubit\", wires=4)\n",
        "dev_test = qml.device(\"lightning.qubit\", wires=4, shots=1000)"
      ],
      "metadata": {
        "id": "E1badQSvISf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Simple Qnode with Dense Angle Encoding for the 8 dimensional inputs,\n",
        "A simple Ring entanglement and parameteried training of input weights\n",
        "and hidden weights. Returns 2 quantum measurables.\n",
        "\"\"\"\n",
        "\n",
        "# @qml.qnode(dev, interface=\"torch\")\n",
        "# def quantum_step(inputs, hidden, weights_in, weights_h):\n",
        "#     #Encoding\n",
        "#     dense_angle_embedding(inputs, wires=[0, 1, 2, 3])\n",
        "#     qml.RY(hidden, wires=3)\n",
        "\n",
        "#     # Interaction Layer/Entanglement\n",
        "#     qml.CNOT(wires=[0, 1])\n",
        "#     qml.CNOT(wires=[1, 2])\n",
        "#     qml.CNOT(wires=[2, 3])\n",
        "#     qml.CNOT(wires=[3, 0])\n",
        "\n",
        "#     # Parametrized trainable unitaries on input wires\n",
        "#     for i in range(3):\n",
        "#         qml.RY(weights_in[i], wires=i)\n",
        "#         qml.RZ(weights_in[i + 3], wires=i)\n",
        "\n",
        "#     # Parametrized unitaries on hidden wire\n",
        "#     qml.RY(weights_h[0], wires=3)\n",
        "#     qml.RZ(weights_h[1], wires=3)\n",
        "\n",
        "#     return qml.expval(qml.PauliZ(2)), qml.expval(qml.PauliZ(3))"
      ],
      "metadata": {
        "id": "MyH4XOByISdZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "5df44359-b340-44c4-c690-1e123fd06559"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nSimple Qnode with Dense Angle Encoding for the 8 dimensional inputs,\\nA simple Ring entanglement and parameteried training of input weights\\nand hidden weights. Returns 2 quantum measurables.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Qnode to process a whole sequence at a time in contrast to the initial attempts at\n",
        "processing a time step at once. It still uses 4 qubit dense angle encoding, but also\n",
        "preserves the the hidden wire's quantum state throughout the sequence processing,\n",
        "which helps avoid re-encoding the hidden state at each time-step.\n",
        "\"\"\"\n",
        "\n",
        "# @qml.qnode(dev, interface=\"autograd\")\n",
        "# def full_sentence_qnode(sentence_embeds, weights_per_word, classifier_weights):\n",
        "#     wires = list(range(n_qubits))\n",
        "\n",
        "#     # Processes a whole sequence (10 words * 8 Dimensional vector embedding)\n",
        "#     for t in range(len(sentence_embeds)):\n",
        "#         dense_angle_embedding(sentence_embeds[t], wires)\n",
        "#         entangle(wires)\n",
        "#         variational_block(weights_per_word[t], wires)\n",
        "\n",
        "#     # Final classifier\n",
        "#     entangle(wires)\n",
        "#     variational_block(classifier_weights, wires)\n",
        "\n",
        "#     return qml.expval(qml.PauliZ(wires[2])), qml.expval(qml.PauliZ(wires[3]))"
      ],
      "metadata": {
        "id": "JE2FDMqB9dwL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "2d1d8f77-ebb2-49d0-b84c-37451e1b641c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nQnode to process a whole sequence at a time in contrast to the initial attempts at\\nprocessing a time step at once. It still uses 4 qubit dense angle encoding, but also\\npreserves the the hidden wire's quantum state throughout the sequence processing,\\nwhich helps avoid re-encoding the hidden state at each time-step.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Akin to the previous iteration QNode, this one processes a whole sequence at a time aswell\n",
        "(10 words - each represented by a 8 dimensional vector). However we have stacked 2 Quantum RNN\n",
        "layers, each seperated by an \"Interaction Layer\" where we perform basic ring topology entanglement.\n",
        "Furthermore there is a final interaction layer, but this layer performs simple RX, RY, RZ rotations\n",
        "instead of entanglement. This is followed by returning the dual quantum measurables.\n",
        "\"\"\"\n",
        "\n",
        "@qml.qnode(dev_train, interface=\"autograd\")\n",
        "def stacked_qrnn_train(x_sequence, flat_params):\n",
        "    wires = list(range(n_qubits))\n",
        "    qrnn_model(x_sequence, flat_params, wires)\n",
        "    return qml.expval(qml.PauliZ(wires[2])), qml.expval(qml.PauliZ(wires[3]))\n",
        "\n",
        "@qml.qnode(dev_test, interface=\"autograd\")\n",
        "def stacked_qrnn_test(x_sequence, flat_params):\n",
        "    wires = list(range(n_qubits))\n",
        "    qrnn_model(x_sequence, flat_params, wires)\n",
        "    return qml.expval(qml.PauliZ(wires[2])), qml.expval(qml.PauliZ(wires[3]))"
      ],
      "metadata": {
        "id": "FdPfadWXrhEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Similar to the previous version, but with an attempt to perform layerwise training in three phases:\n",
        "a. Phase - 1: Input Layer -> QRNN Layer 1 -> Interaction Layer 1\n",
        "b. Phase - 2: Input Layer -> QRNN Layer 1 -> Interaction Layer 1 -> QRNN Layer 2 -> Interaction Layer 2\n",
        "c. Phase - 3: Input Layer -> QRNN Layer 1 -> Interaction Layer 1 -> QRNN Layer 2 -> Interaction Layer 2 -> Interaction Layer 3\n",
        "\n",
        "Incremently trains and freezes the trainable parameters of previous layers added. This is being performed\n",
        "in an attempt to mitigate the barren plateau issue being encountered in the previous version of the stacked QRNN.\n",
        "\"\"\"\n",
        "\n",
        "# @qml.qnode(dev, interface=\"autograd\")\n",
        "# def stacked_qrnn(x_sequence, flat_params, mode=\"full\"):\n",
        "#     wires = list(range(n_qubits))\n",
        "#     qrnn_model(x_sequence, flat_params, wires, mode=mode)\n",
        "#     return qml.expval(qml.PauliZ(wires[2])), qml.expval(qml.PauliZ(wires[3]))"
      ],
      "metadata": {
        "id": "sGJEJ4QDCuKD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "c33da8fb-891d-47aa-ceb6-6621621e6429"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nSimilar to the previous version, but with an attempt to perform layerwise training in three phases:\\na. Phase - 1: Input Layer -> QRNN Layer 1 -> Interaction Layer 1\\nb. Phase - 2: Input Layer -> QRNN Layer 1 -> Interaction Layer 1 -> QRNN Layer 2 -> Interaction Layer 2\\nc. Phase - 3: Input Layer -> QRNN Layer 1 -> Interaction Layer 1 -> QRNN Layer 2 -> Interaction Layer 2 -> Interaction Layer 3\\n\\nIncremently trains and freezes the trainable parameters of previous layers added. This is being performed\\nin an attempt to mitigate the barren plateau issue being encountered in the previous version of the stacked QRNN.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Parameter Initialization**"
      ],
      "metadata": {
        "id": "qvRycYz9rG81"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# weights_in = np.random.uniform(0, 2 * np.pi, size=6)\n",
        "# weights_h  = np.random.uniform(0, 2 * np.pi, size=2)\n",
        "# optimizer = AdamOptimizer(stepsize=0.01)\n",
        "# epochs = 20"
      ],
      "metadata": {
        "id": "Zvh3XimdrK9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# weights_per_word = qml.numpy.array(np.random.uniform(0, 2*np.pi, (10, 8)), requires_grad=True)\n",
        "# classifier_weights = qml.numpy.array(np.random.uniform(0, 2*np.pi, (8,)), requires_grad=True)\n",
        "\n",
        "# flat_params = qml.numpy.concatenate([\n",
        "#     weights_per_word.flatten(),\n",
        "#     classifier_weights.flatten()\n",
        "# ])\n",
        "\n",
        "# optimizer = AdamOptimizer(stepsize=0.01)\n",
        "# epochs = 60"
      ],
      "metadata": {
        "id": "ikln0pq9rK60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flat_params = qml.numpy.array(\n",
        "    np.random.normal(0, 0.01, size=(48,)),\n",
        "    requires_grad=True\n",
        ")\n",
        "\n",
        "optimizer = AdamOptimizer(stepsize=0.005)\n",
        "epochs = 80"
      ],
      "metadata": {
        "id": "TYgq2DYYth7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Phase - 1\n",
        "# flat_params = qml.numpy.array(\n",
        "#     np.random.normal(0, 0.01, size=(12,)),\n",
        "#     requires_grad=True)\n",
        "\n",
        "# # Phase - 2\n",
        "# phase2 = qml.numpy.array(np.random.normal(0, 0.01, size=(12,)), requires_grad=True)\n",
        "# flat_params = qml.numpy.concatenate([phase1, phase2])\n",
        "\n",
        "# # Phase - 3\n",
        "# phase3 = qml.numpy.array(np.random.normal(0, 0.01, size=(12,)), requires_grad=True)\n",
        "# flat_params = qml.numpy.concatenate([phase1, phase2, phase3])\n",
        "\n",
        "# optimizer = qml.optimize.AdamOptimizer(stepsize=0.005)\n",
        "# epochs = 20"
      ],
      "metadata": {
        "id": "Dar3GsKpQZy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Directory Creation**"
      ],
      "metadata": {
        "id": "MjYGEijbc7yy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = \"/content/drive/MyDrive/QML-Research/Analysis\"\n",
        "\n",
        "folders_to_create = [\n",
        "    \"logs/qrnn_outputs\",\n",
        "    \"plots/loss_trend\",\n",
        "    \"plots/accuracy_trend\",\n",
        "    \"plots/test_boxplots\",\n",
        "]\n",
        "\n",
        "for folder in folders_to_create:\n",
        "    path = os.path.join(base_dir, folder)\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "    print(f\"Created (or already exists): {path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSUjeQ-BdAYy",
        "outputId": "fc71562e-19c0-41d3-a775-7de00172ae24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created (or already exists): /content/drive/MyDrive/QML-Research/Analysis/logs/qrnn_outputs\n",
            "Created (or already exists): /content/drive/MyDrive/QML-Research/Analysis/plots/loss_trend\n",
            "Created (or already exists): /content/drive/MyDrive/QML-Research/Analysis/plots/accuracy_trend\n",
            "Created (or already exists): /content/drive/MyDrive/QML-Research/Analysis/plots/test_boxplots\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training**"
      ],
      "metadata": {
        "id": "Ce4aLIso4byH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = []\n",
        "train_accuracies = []\n",
        "\n",
        "print(\"Training Loop\\n\")\n",
        "# print(\"Phase 3: Training QRNN Layer 2\")\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    epoch_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    epoch_start = time.time()\n",
        "\n",
        "    for xb, yb in train_loader:\n",
        "        x_np = xb.squeeze(0).numpy()\n",
        "        y_np = yb.item()\n",
        "        x_qml = qml.numpy.array(x_np, requires_grad=False)\n",
        "\n",
        "        def cost(flat_params):\n",
        "          # wpw, clf = reshape_params(flat_params)\n",
        "          # logits = full_sentence_qnode(x_qml, wpw, clf)\n",
        "          # logits = stacked_qrnn(x_qml, flat_params, mode = \"phase3\")\n",
        "          logits = stacked_qrnn_train(x_qml, flat_params)\n",
        "          logits = qml.numpy.array(logits)\n",
        "          probs = softmax(logits)\n",
        "          return cross_entropy(y_np, probs)\n",
        "\n",
        "        # weights_in, weights_h = optimizer.step(cost, (weights_in, weights_h))\n",
        "        # logits = forward(x_np, weights_in, weights_h)\n",
        "        grad = qml.grad(cost)(flat_params)\n",
        "        grad_norm = qml.numpy.linalg.norm(grad)\n",
        "        flat_params = optimizer.step(cost, flat_params)\n",
        "        # weights_per_word, classifier_weights = reshape_params(flat_params)\n",
        "        # logits = full_sentence_qnode(x_qml, weights_per_word, classifier_weights)\n",
        "        # logits = stacked_qrnn(x_qml, flat_params, mode = \"phase3\")\n",
        "        logits = stacked_qrnn_train(x_qml, flat_params)\n",
        "        probs = softmax(logits)\n",
        "        loss = cross_entropy(y_np, probs)\n",
        "\n",
        "        pred_label = qml.numpy.argmax(probs)\n",
        "\n",
        "        if pred_label == y_np:\n",
        "            correct += 1\n",
        "        epoch_loss += loss\n",
        "        total += 1\n",
        "\n",
        "    avg_loss = epoch_loss / total\n",
        "    acc = correct / total\n",
        "\n",
        "    train_losses.append(avg_loss)\n",
        "    train_accuracies.append(acc)\n",
        "\n",
        "    epoch_time = time.time() - epoch_start\n",
        "    print(f\"Epoch {epoch:02d} | Loss: {avg_loss:.4f} | Acc: {acc:.4f} | Grad Norm: {grad_norm:.6f} | Time: {epoch_time:.2f}s\")\n",
        "\n",
        "total_time = time.time() - start_time\n",
        "print(f\"\\nTraining complete in {total_time:.2f} seconds.\")\n",
        "\n",
        "\n",
        "# print(f\"\\nPhase 3 complete in {total_time:.2f} seconds.\")\n",
        "# phase1 = qml.numpy.array(flat_params, requires_grad=False)\n",
        "# phase2 = qml.numpy.array(flat_params[12:], requires_grad=False)\n",
        "# phase3 = qml.numpy.array(flat_params[24:], requires_grad=False)"
      ],
      "metadata": {
        "id": "qOG0mTOZa7B4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Phase Weights Save**"
      ],
      "metadata": {
        "id": "eESQkrqgUsle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving phase-1 trained parameters\n",
        "# with open(\"/content/drive/MyDrive/QML-Research/Model Saves/Phase_Saves/phase1.pkl\", \"wb\") as f:\n",
        "#     pickle.dump(phase1, f)\n",
        "\n",
        "# # # Saving phase-2 trained parameters\n",
        "# with open(\"/content/drive/MyDrive/QML-Research/Model Saves/Phase_Saves/phase2.pkl\", \"wb\") as f:\n",
        "#     pickle.dump(phase2, f)\n",
        "\n",
        "# # Saving phase-3 trained parameters\n",
        "# with open(\"/content/drive/MyDrive/QML-Research/Model Saves/Phase_Saves/phase3.pkl\", \"wb\") as f:\n",
        "#     pickle.dump(phase3, f)"
      ],
      "metadata": {
        "id": "_b6zv1L6UTzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Phase Weights Load**"
      ],
      "metadata": {
        "id": "eZgdRPDVUxX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Loading Phase-1 Weights\n",
        "# with open(\"/content/drive/MyDrive/QML-Research/Model Saves/Phase_Saves/phase1.pkl\", \"rb\") as f:\n",
        "#     phase1 = pickle.load(f)\n",
        "#     phase1 = qml.numpy.array(phase1, requires_grad=False)\n",
        "\n",
        "# #Loading Phase-2 Weights\n",
        "# with open(\"/content/drive/MyDrive/QML-Research/Model Saves/Phase_Saves/phase2.pkl\", \"rb\") as f:\n",
        "#     phase2 = pickle.load(f)\n",
        "#     phase2 = qml.numpy.array(phase2, requires_grad=False)\n",
        "\n",
        "# # #Loading Phase-3 Weights\n",
        "# with open(\"/content/drive/MyDrive/QML-Research/Model Saves/Phase_Saves/phase3.pkl\", \"rb\") as f:\n",
        "#     phase3 = pickle.load(f)\n",
        "#     phase3 = qml.numpy.array(phase3, requires_grad=False)"
      ],
      "metadata": {
        "id": "sLEKz4_bU0L4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Testing**"
      ],
      "metadata": {
        "id": "VODeSsL-4dSr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def evaluate_test(weights_in, weights_h):\n",
        "# def evaluate_test(weights_per_word, classifier_weights):\n",
        "def evaluate_test(flat_params):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    test_loss = 0\n",
        "\n",
        "    for xb, yb in test_loader:\n",
        "        x_np = xb.squeeze(0).numpy()\n",
        "        y_np = yb.item()\n",
        "        x_qml = qml.numpy.array(x_np, requires_grad=False)\n",
        "\n",
        "        # logits = full_sentence_qnode(x_qml, weights_per_word, classifier_weights)\n",
        "        logits = stacked_qrnn_test(x_qml, flat_params)\n",
        "        probs = softmax(logits)\n",
        "        loss = cross_entropy(y_np, probs)\n",
        "\n",
        "        pred = qml.numpy.argmax(probs)\n",
        "\n",
        "        if pred == y_np:\n",
        "            correct += 1\n",
        "        test_loss += loss\n",
        "        total += 1\n",
        "\n",
        "    return test_loss / total, correct / total"
      ],
      "metadata": {
        "id": "chAp3V1Ba692"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Logging**"
      ],
      "metadata": {
        "id": "aJUnYQXIhCuw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def log_test_results(model_name, test_acc, test_loss):\n",
        "    log_path = \"/content/drive/MyDrive/QML-Research/Analysis/logs/qrnn_outputs/accuracy_logs.txt\"\n",
        "\n",
        "    with open(log_path, \"a\") as f:\n",
        "        f.write(f\"[Model: {model_name}]\\n\")\n",
        "        f.write(f\"Test Accuracy: {test_acc:.4f}\\n\")\n",
        "        f.write(f\"Test Loss: {test_loss:.4f}\\n\\n\")\n",
        "\n",
        "    print(f\"Logged test results to: {log_path}\")"
      ],
      "metadata": {
        "id": "veWHFuY3fVo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_training_plots(model_name, train_losses, train_accuracies):\n",
        "    base_path = \"/content/drive/MyDrive/QML-Research/Analysis/plots\"\n",
        "\n",
        "    # Loss Plot\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(train_losses, label=\"Training Loss\")\n",
        "    plt.title(f\"{model_name} - Loss Trend\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{base_path}/loss_trend/loss_plot_{model_name}.png\")\n",
        "    plt.close()\n",
        "\n",
        "    # Accuracy Plot\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(train_accuracies, label=\"Training Accuracy\", color='green')\n",
        "    plt.title(f\"{model_name} - Accuracy Trend\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{base_path}/accuracy_trend/acc_plot_{model_name}.png\")\n",
        "    plt.close()\n",
        "\n",
        "    print(f\"Plots saved to: {base_path}/loss_trend/ and /accuracy_trend/\")"
      ],
      "metadata": {
        "id": "x-bwkU_FfVmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test_loss, test_acc = evaluate_test(weights_in, weights_h)\n",
        "# test_loss, test_acc = evaluate_test(weights_per_word, classifier_weights)\n",
        "# flat_params = qml.numpy.concatenate([phase1, phase2, phase3])\n",
        "test_loss, test_acc = evaluate_test(flat_params)\n",
        "log_test_results(\"Stacked_3Layer_v3\", test_acc, test_loss)\n",
        "save_training_plots(\"Stacked_3Layer_v3\", train_losses, train_accuracies)"
      ],
      "metadata": {
        "id": "niKaK4AJfVjB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22ca724d-bd63-47fd-e181-fd305ed4acd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logged test results to: /content/drive/MyDrive/QML-Research/Analysis/logs/qrnn_outputs/accuracy_logs.txt\n",
            "Plots saved to: /content/drive/MyDrive/QML-Research/Analysis/plots/loss_trend/ and /accuracy_trend/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Saving and Loading**"
      ],
      "metadata": {
        "id": "Stu8Vrh9hL9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/QML-Research/Model Saves/3Layer_QRNN_No_Intermediate_Interaction.pkl', 'wb') as f:\n",
        "    pickle.dump(flat_params, f)\n",
        "\n",
        "print(\"Saved Model parameters\")"
      ],
      "metadata": {
        "id": "VbBL3qvshQ63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "092ff525-890e-4361-eab0-0f7015e45105"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved Model parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/QML-Research/Models/stacked_qrnn_v6_params.pkl', 'rb') as f:\n",
        "    flat_params = pickle.load(f)\n",
        "\n",
        "weights_per_word, classifier_weights = reshape_params(flat_params)\n",
        "print(\"Model parameters loaded\")"
      ],
      "metadata": {
        "id": "Yl65GX_UiGTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Test Inference**"
      ],
      "metadata": {
        "id": "5r-VF2IWe1lJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trial_sentences = [\n",
        "    \"This charger is amazing, super fast and highly reliable.\",\n",
        "    \"Worst headphones ever bought, awful sound and terrible build quality.\",\n",
        "    \"Very satisfied with camera quality considering the affordable price range.\",\n",
        "    \"Product stopped working completely within one week of regular usage.\",\n",
        "    \"Excellent screen resolution, great brightness and strong battery backup too.\",\n",
        "    \"This is the best light bulb I’ve ever used.\",\n",
        "    \"Did not match the description, complete waste of my money.\",\n",
        "    \"This chair feels sturdy, comfortable, and worth every single penny.\",\n",
        "    \"Absolutely love this phone case, protective, stylish and well-made.\",\n",
        "    \"Speaker quality is poor, distorts quickly at medium volume levels.\",\n",
        "    \"Delivery arrived quickly with excellent packaging and no visible damages.\",\n",
        "    \"Avoid this item entirely, cheap build and constantly stops working.\",\n",
        "    \"Best pair of scissors ever purchased, sharp, durable and reliable.\"\n",
        "]\n",
        "\n",
        "def preprocess_for_inference(sent_list):\n",
        "    encoded_sents = []\n",
        "\n",
        "    for sentence in sent_list:\n",
        "        tokens = clean_and_tokenize(sentence)\n",
        "        if len(tokens) < max_len:\n",
        "            tokens += [\"<PAD>\"] * (max_len - len(tokens))\n",
        "        else:\n",
        "            tokens = tokens[:max_len]\n",
        "\n",
        "        vec = sentence_to_vec(tokens, reduced_embeddings, dim=8)\n",
        "        vec = np.array(vec)\n",
        "        vec = (vec - X_embed_np.min()) * (np.pi / (X_embed_np.max() - X_embed_np.min()))\n",
        "        encoded_sents.append(vec)\n",
        "\n",
        "    return encoded_sents\n",
        "\n",
        "encoded_inputs = preprocess_for_inference(trial_sentences)\n",
        "\n",
        "for sent, input_vec in zip(trial_sentences, encoded_inputs):\n",
        "    x_qml = qml.numpy.array(input_vec, requires_grad=False)\n",
        "    logits = stacked_qrnn_test(x_qml, flat_params)\n",
        "    probs = softmax(logits)\n",
        "    pred = qml.numpy.argmax(probs)\n",
        "\n",
        "    sentiment = \"Positive\" if pred == 1 else \"Negative\"\n",
        "    print(f\"Sentence: \\\"{sent}\\\"\\nPredicted Sentiment: {sentiment} ({pred})\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJCzUM2Me1Ie",
        "outputId": "e9f6c5ef-4c67-4799-bb0d-a50955a4f9b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: \"This charger is amazing, super fast and highly reliable.\"\n",
            "Predicted Sentiment: Negative (0)\n",
            "\n",
            "Sentence: \"Worst headphones ever bought, awful sound and terrible build quality.\"\n",
            "Predicted Sentiment: Positive (1)\n",
            "\n",
            "Sentence: \"Very satisfied with camera quality considering the affordable price range.\"\n",
            "Predicted Sentiment: Negative (0)\n",
            "\n",
            "Sentence: \"Product stopped working completely within one week of regular usage.\"\n",
            "Predicted Sentiment: Positive (1)\n",
            "\n",
            "Sentence: \"Excellent screen resolution, great brightness and strong battery backup too.\"\n",
            "Predicted Sentiment: Negative (0)\n",
            "\n",
            "Sentence: \"This is the best light bulb I’ve ever used.\"\n",
            "Predicted Sentiment: Negative (0)\n",
            "\n",
            "Sentence: \"Did not match the description, complete waste of my money.\"\n",
            "Predicted Sentiment: Negative (0)\n",
            "\n",
            "Sentence: \"This chair feels sturdy, comfortable, and worth every single penny.\"\n",
            "Predicted Sentiment: Negative (0)\n",
            "\n",
            "Sentence: \"Absolutely love this phone case, protective, stylish and well-made.\"\n",
            "Predicted Sentiment: Negative (0)\n",
            "\n",
            "Sentence: \"Speaker quality is poor, distorts quickly at medium volume levels.\"\n",
            "Predicted Sentiment: Negative (0)\n",
            "\n",
            "Sentence: \"Delivery arrived quickly with excellent packaging and no visible damages.\"\n",
            "Predicted Sentiment: Negative (0)\n",
            "\n",
            "Sentence: \"Avoid this item entirely, cheap build and constantly stops working.\"\n",
            "Predicted Sentiment: Positive (1)\n",
            "\n",
            "Sentence: \"Best pair of scissors ever purchased, sharp, durable and reliable.\"\n",
            "Predicted Sentiment: Positive (1)\n",
            "\n"
          ]
        }
      ]
    }
  ]
}